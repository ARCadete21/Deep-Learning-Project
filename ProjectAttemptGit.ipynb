{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7c1480",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:01:51.038576700Z",
     "start_time": "2023-11-18T22:01:44.189341400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f0bf4",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5fa94f466d884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:01:55.420804Z",
     "start_time": "2023-11-18T22:01:54.593842900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "project_path = 'C:\\\\Users\\\\Martin\\\\OneDrive - NOVAIMS\\\\Documents\\\\Universidade\\\\3ยบ Ano\\\\Deep Learning\\\\Project'\n",
    "\n",
    "# As we know, there are 2 folders with images, one for training and one for testing, and there is also the metadata of all those pictures in a single excel file.\n",
    "# Let's load the csv file and see what it looks like.\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(project_path, 'HAM10000_metadata.csv'))\n",
    "\n",
    "# Now to get all the images from the train folder\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(project_path, '*', '*.jpg'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da296482",
   "metadata": {},
   "source": [
    "## Train, Test Slip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d810cf1cf5949c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:04:03.728352Z",
     "start_time": "2023-11-18T22:01:57.086864500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can add a new column to the dataframe with the path to the image\n",
    "metadata['path'] = metadata['image_id'].map(imageid_path_dict.get)\n",
    "\n",
    "# We can also add a column with the actual image\n",
    "metadata['image'] = metadata['path'].map(lambda x: cv2.imread(x))\n",
    "\n",
    "# Let's now separate the dataset into train and test based on whether train or test is in the path\n",
    "train = metadata[metadata['path'].str.contains(\"train\")]\n",
    "test = metadata[metadata['path'].str.contains(\"test\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce6d9c",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db9ea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.lesion_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72063c40",
   "metadata": {},
   "source": [
    "Let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89550a65db8b1d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T18:51:32.074790900Z",
     "start_time": "2023-11-18T18:51:32.055705200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset='lesion_id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b42a7",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "Using categorical data is not the best approach, we will use `LabelEncoder` to transform the target column into *numerical values*, which we will then use the function `to_categorical` to transform into *one-hot encoding*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568dcac9cf80f843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:04:03.738254700Z",
     "start_time": "2023-11-18T22:04:03.730353200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train['CancerType'] = label_encoder.fit_transform(train['dx'])\n",
    "test['CancerType'] = label_encoder.fit_transform(test['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1dc5c72dbf6e931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:09:35.105139900Z",
     "start_time": "2023-11-16T20:09:28.175665500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>CancerType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0002761</td>\n",
       "      <td>ISIC_0029176</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0    male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear   \n",
       "6  HAM_0002761  ISIC_0029176  bkl   histo  60.0    male         face   \n",
       "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back   \n",
       "\n",
       "                                                path image  CancerType  \n",
       "0  C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...  None           2  \n",
       "2  C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...  None           2  \n",
       "4  C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...  None           2  \n",
       "6  C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...  None           2  \n",
       "8  C:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\U...  None           2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check of the values in the training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebf46d1f2865350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:46:17.223249500Z",
     "start_time": "2023-11-17T15:46:17.217189500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "nv       4253\n",
       "bkl       603\n",
       "mel       534\n",
       "bcc       280\n",
       "akiec     189\n",
       "vasc       80\n",
       "df         59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train['dx'].value_counts()\n",
    "# make sense to leave this here since marcel did the transformation  two cells ago from \"dx\" to \"CancerType\"??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8739fad96593b0c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:46:47.453904600Z",
     "start_time": "2023-11-17T15:46:47.447279700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CancerType\n",
       "5    4253\n",
       "2     603\n",
       "4     534\n",
       "1     280\n",
       "0     189\n",
       "6      80\n",
       "3      59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for unbalances\n",
    "train['CancerType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbee2ae6ccbc9b4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Balancing the Dataset\n",
    "As we saw before, the dataset is not balanced, so we should balance it before training the model.\n",
    "Some of the approaches we can use are:\n",
    "- Undersampling\n",
    "- Oversampling\n",
    "- SMOTE\n",
    "- Class Weights\n",
    "- Ensemble Methods\n",
    "- Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff55aaa",
   "metadata": {},
   "source": [
    "We should extract the `target` column from both train and test and remove it from their dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4db22b32551813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:04:03.757831200Z",
     "start_time": "2023-11-18T22:04:03.737253300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train[['image_id', 'CancerType']]\n",
    "y_train.set_index('image_id', inplace=True)\n",
    "y_train = to_categorical(y_train, num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6082057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[['image_id', 'CancerType']]\n",
    "y_test.set_index('image_id', inplace=True)\n",
    "y_test = to_categorical(y_test, num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e4a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['dx', 'CancerType'], axis=1)\n",
    "X.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcb96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['dx', 'CancerType'], axis=1)\n",
    "X_test.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4ed2ec3df7082b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:21:02.139446100Z",
     "start_time": "2023-11-18T22:21:02.128607900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_class_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Martin\\OneDrive - NOVAIMS\\Documents\\Universidade\\3ยบ Ano\\Deep Learning\\Project\\ProjectAttemptGit.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Martin/OneDrive%20-%20NOVAIMS/Documents/Universidade/3%C2%BA%20Ano/Deep%20Learning/Project/ProjectAttemptGit.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_integers \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_train, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Martin/OneDrive%20-%20NOVAIMS/Documents/Universidade/3%C2%BA%20Ano/Deep%20Learning/Project/ProjectAttemptGit.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m class_weights \u001b[39m=\u001b[39m compute_class_weight(class_weight \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Martin/OneDrive%20-%20NOVAIMS/Documents/Universidade/3%C2%BA%20Ano/Deep%20Learning/Project/ProjectAttemptGit.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                   classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_integers),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Martin/OneDrive%20-%20NOVAIMS/Documents/Universidade/3%C2%BA%20Ano/Deep%20Learning/Project/ProjectAttemptGit.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                   y \u001b[39m=\u001b[39m y_integers)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Martin/OneDrive%20-%20NOVAIMS/Documents/Universidade/3%C2%BA%20Ano/Deep%20Learning/Project/ProjectAttemptGit.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m d_class_weights \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39menumerate\u001b[39m(class_weights))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_class_weight' is not defined"
     ]
    }
   ],
   "source": [
    "y_integers = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight(class_weight = 'balanced',\n",
    "                                                  classes = np.unique(y_integers),\n",
    "                                                  y = y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638fd469a19393d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T17:11:16.714403500Z",
     "start_time": "2023-11-17T17:11:16.711366400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4eee424a3a1383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T16:07:01.018922100Z",
     "start_time": "2023-11-17T16:06:54.282413400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e407c088c7e3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T16:07:18.643545800Z",
     "start_time": "2023-11-17T16:07:11.930927100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6eed81f45d23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T16:09:04.832713800Z",
     "start_time": "2023-11-17T16:09:04.826306300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d48cfe11d5138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:09:23.583884300Z",
     "start_time": "2023-11-18T22:09:21.612269500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the images to numpy arrays\n",
    "X_image = np.asarray(X['image'].tolist())\n",
    "X_test_image = np.asarray(X_test['image'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a00f1188b5b183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T17:13:24.289349700Z",
     "start_time": "2023-11-17T17:13:24.281181Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e416d6c97150a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T16:12:21.765804500Z",
     "start_time": "2023-11-17T16:12:21.759585Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e99d872a36224",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Verify data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9e448d0cf54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:50:02.143992800Z",
     "start_time": "2023-11-17T15:50:02.141992800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_dimensions(image_list):\n",
    "    \"\"\"\n",
    "    This function prints the largest and smallest dimensions of the images in the list\n",
    "    Args:\n",
    "        image_list: list of images\n",
    "    \"\"\"\n",
    "    \n",
    "    # List for storing image dimensions\n",
    "    largest_width, largest_height = 0, 0\n",
    "    smallest_width, smallest_height = float('inf'), float('inf')\n",
    "    \n",
    "    for image in image_list:\n",
    "        # Get the width and height of the image\n",
    "        height, width, _ = image.shape\n",
    "    \n",
    "        # Update largest and smallest dimensions if necessary\n",
    "        largest_width = max(largest_width, width)\n",
    "        largest_height = max(largest_height, height)\n",
    "        smallest_width = min(smallest_width, width)\n",
    "        smallest_height = min(smallest_height, height)\n",
    "        \n",
    "    print(\"Largest Image : {}x{}\".format(largest_width, largest_height))\n",
    "    print(\"Smallest Image : {}x{}\".format(smallest_width, smallest_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71981b87882fa071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T15:51:00.988132300Z",
     "start_time": "2023-11-17T15:51:00.977620Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_image_dimensions(X_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a8819c0d16f12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "All images have the same size, so we don't need to resize them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ecdebf3559394",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77be257a549afc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:04:03.778254800Z",
     "start_time": "2023-11-18T22:04:03.761832400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_contrast_enhancement(images_data, size = (299, 224), alpha = 1.3, beta = 0.5, display = False):\n",
    "    \"\"\"\n",
    "    This function applies contrast enhancement to the images in a dataset.\n",
    "    Args:\n",
    "        images_data: list of images\n",
    "        size: size to which the images should be resized\n",
    "        alpha: contrast control (1.0 means no change)\n",
    "        beta: brightness control (0 means no change)\n",
    "        display: whether to display the images before and after the contrast enhancement\n",
    "    Returns:\n",
    "        images_data_processed: numpy array of processed images\n",
    "    \"\"\"\n",
    "\n",
    "    # Lists to store the processed images\n",
    "    images_data_processed = []\n",
    "\n",
    "    # Apply contrast enhancement to each image\n",
    "    for img in images_data:\n",
    "        # Resize it\n",
    "        img = cv2.resize(img, size)\n",
    "\n",
    "        # Apply contrast enhancement\n",
    "        enhanced_img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "        # Append the processed image to the list\n",
    "        images_data_processed.append(enhanced_img)\n",
    "\n",
    "    # Convert the processed lists to numpy arrays\n",
    "    images_data_processed = np.array(images_data_processed)\n",
    "\n",
    "    # Display first 6 images and compare them with the original images\n",
    "    if display:\n",
    "        fig, ax = plt.subplots(1, 6, figsize=(15, 15))\n",
    "        for i in range(6):\n",
    "            ax[i].imshow(images_data[i])\n",
    "            ax[i].set_title(\"Original Image\")\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots(1, 6, figsize=(15, 15))\n",
    "        for i in range(6):\n",
    "            ax[i].imshow(images_data_processed[i])\n",
    "            ax[i].set_title(\"Contrast Enhanced Image\")\n",
    "        plt.show()\n",
    "    return images_data_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093327553de653c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:10:01.578109700Z",
     "start_time": "2023-11-18T22:09:56.678255700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_processed = apply_contrast_enhancement(X_image,alpha = 1.15, beta=4, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece1930c578d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T21:46:39.633517600Z",
     "start_time": "2023-11-18T21:46:37.263943Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_processed = apply_contrast_enhancement(X_test_image,alpha = 1.15, beta=4, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0acf98049d579",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Image Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f71c440034d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:12:00.885930100Z",
     "start_time": "2023-11-18T22:12:00.882943100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IDG = ImageDataGenerator(rescale= 1./255,\n",
    "                             rotation_range=35,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             zoom_range = 0.12, # Randomly zoom image\n",
    "                             width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             vertical_flip=True # randomly flip images\n",
    "                                )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059db5dd53249d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:10:55.022794800Z",
     "start_time": "2023-11-18T22:10:54.595986400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_processed, y_train, test_size=0.2, stratify=y_train, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfebad4e0466518",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c815ee1d2ff8af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T22:12:44.200962700Z",
     "start_time": "2023-11-18T22:12:32.911522100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDG.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759252e89f010a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:22:33.127807800Z",
     "start_time": "2023-11-16T20:22:33.047636400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662563a3c5d72220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:23:07.779891300Z",
     "start_time": "2023-11-16T20:23:07.775064300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727acc4c8b287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T23:47:04.792963600Z",
     "start_time": "2023-11-18T23:47:04.443917800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import (\n",
    "    ResNet50,\n",
    "    InceptionV3,\n",
    "    DenseNet121,\n",
    "    VGG16,\n",
    "    Xception)\n",
    "\n",
    "\n",
    "base_model= tensorflow.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 299, 3),\n",
    "    pooling=None,\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dense(728, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(728, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ebe4ada26b7e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T00:12:29.211249200Z",
     "start_time": "2023-11-18T23:47:37.827323100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(IDG.flow(X_train, Y_train, batch_size=128), epochs=7 , validation_data=(X_val, Y_val), callbacks=[early_stop] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659b80cf54d166c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(IDG.flow(X_processed, y_train, batch_size=32), epochs=5, callbacks=[early_stop], class_weight=d_class_weights, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b33a945bddb64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T22:00:40.023758100Z",
     "start_time": "2023-11-16T22:00:39.652494500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0ddccd011a666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:09:44.286044600Z",
     "start_time": "2023-11-16T20:09:44.273932600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's now split the train dataset into train and validation\n",
    "#X_train, X_val, y_train_2, y_val = train_test_split(df_train, y_train, test_size=0.2, random_state=42, stratify=y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5e39f6a4d640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:09:44.297725600Z",
     "start_time": "2023-11-16T20:09:44.284045800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_train_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914c347a4de313c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f750eae4497669d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:09:44.342641300Z",
     "start_time": "2023-11-16T20:09:44.293725700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can see that the dataset is not balanced at all, so we should use class weights to compensate for that\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                 np.unique(y_train_2),\n",
    " #                                                y_train_2)\n",
    "\n",
    "#class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
